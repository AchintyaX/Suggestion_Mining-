{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EooymfXn-jZ_"
   },
   "source": [
    "#  MIDAS IIITD Summer Internship task(NLP Problem)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DbdgjzWt-jaB"
   },
   "outputs": [],
   "source": [
    "# importing all the necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j1NBAg99-jaG"
   },
   "source": [
    "### Getting the datasets for the task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jYBpiEob-jaI"
   },
   "outputs": [],
   "source": [
    "# setting up the data for training, testing and evaluation\n",
    "\n",
    "train = pd.read_csv(\"https://raw.githubusercontent.com/Semeval2019Task9/Subtask-A/master/V1.4_Training.csv\", header=None, encoding='latin1')\n",
    "test = pd.read_csv(\"https://raw.githubusercontent.com/Semeval2019Task9/Subtask-A/master/SubtaskA_Trial_Test_Labeled.csv\", encoding='latin1')\n",
    "evaluation = pd.read_csv('https://raw.githubusercontent.com/Semeval2019Task9/Subtask-A/master/SubtaskA_EvaluationData.csv', header=None, encoding='latin1')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3ibpfC6x-jaL"
   },
   "source": [
    "We would be using one hot encoding because many machine learning algorithms don't work with categorical data directly\n",
    "The categories must be converted into numbers. This is required for both input and output variables that are categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "AozIfbJl-jaN",
    "outputId": "c145e96d-7f05-4a2b-c44c-192e8cea9ede"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras \n",
    "\n",
    "# the functions helps us to transform labels into one-hot encoded arrays\n",
    "def transform_labels(y):\n",
    "    return keras.utils.to_categorical(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5lJR-3X2-jaU"
   },
   "source": [
    "### demarking the training, testing and evaluation datasets into text and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kFbhamwJ-jaV"
   },
   "outputs": [],
   "source": [
    "#training data\n",
    "x_train = train[1]\n",
    "y_train = train[2]\n",
    "y_train_con = transform_labels(y_train)\n",
    "\n",
    "#testing data\n",
    "x_test = test['sentence']\n",
    "y_test = test['label']\n",
    "y_test_con = transform_labels(y_test)\n",
    "\n",
    "#evaluation data\n",
    "x_eval = evaluation[1]\n",
    "x_eval = x_eval.str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "d39GNidB-jaZ"
   },
   "source": [
    "# Preprocessing the data \n",
    "One of the most important step in Natural Language Processing is data preprocessing. It is very important to remove data of all the unneccessary elements and make it uniform so that it is easier for the computer to process the data and also to ensure that redundant components which make no actual contribution are mistaken by the algorithm and then assigned weight.\n",
    "Some steps that I wish to take in preprocessing of the data here are -\n",
    "1. converting all text to unicode\n",
    "2. expand all contractions like won't -> will not\n",
    "3. remove special characters \n",
    "4. Lemmatize the text- that is converting the words to there base form\n",
    "5. convert the whole text into lower case so that the feature vector of two words which are just different in casing are not made"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "id": "12LDd1YC-jaa",
    "outputId": "d152df1c-b9f0-4ccd-c7ba-914d5305e8f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting contractions\n",
      "  Downloading https://files.pythonhosted.org/packages/52/52/a15f0fb338a462045c7c87a35dbaeda11738c45aa9d2f5c76ac191d6adff/contractions-0.0.17-py2.py3-none-any.whl\n",
      "Installing collected packages: contractions\n",
      "Successfully installed contractions-0.0.17\n"
     ]
    }
   ],
   "source": [
    "!pip install contractions\n",
    "# importing libraries for preprocessing the text \n",
    "\n",
    "import spacy \n",
    "import re\n",
    "import contractions\n",
    "import unicodedata "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2C-g92v5-jae"
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aVHGCBdZ-jai"
   },
   "outputs": [],
   "source": [
    "# conversion to unicode\n",
    "def uni_convert(text):\n",
    "    text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "    return text\n",
    "\n",
    "# function expands contractions present in the text \n",
    "def expand(text):\n",
    "    return contractions.fix(text)\n",
    "\n",
    "# function removes special characters from the text\n",
    "def remove_special_characters(text, remove_digits=False):\n",
    "    pattern = r'[^a-zA-z0-9\\s]' if not remove_digits else r'[^a-zA-z\\s]'\n",
    "    text = re.sub(pattern, '', text)\n",
    "    return text\n",
    "\n",
    "# lemmatization of the text\n",
    "def lemmatize(text):\n",
    "    text = nlp(text)\n",
    "    text = ' '.join([word.lemma_ if word.lemma_ != '-PRON-' else word.text for word in text])\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oLka-gIO-jan"
   },
   "outputs": [],
   "source": [
    "import tqdm # to show progress bar \n",
    "\n",
    "def preprocess(text):\n",
    "    \n",
    "    normalized_text = []\n",
    "    \n",
    "    for doc in tqdm.tqdm(text):\n",
    "        doc = doc.lower()\n",
    "        doc = uni_convert(doc)\n",
    "        doc = expand(doc)\n",
    "        doc = re.sub(r'[\\r|\\n|\\r\\n]+', ' ',doc)\n",
    "        doc = lemmatize(doc)\n",
    "        \n",
    "        special_character_pattern = re.compile(r'([{.(-)!}])')\n",
    "        doc = special_character_pattern.sub(\" \\\\1 \", doc)\n",
    "        doc = remove_special_characters(doc, remove_digits=True)\n",
    "        doc = re.sub(' +', ' ', doc)\n",
    "        normalized_text.append(doc)\n",
    "    return normalized_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "AdpCKkJ4-jas",
    "outputId": "462fbf37-d1ab-483a-a9b6-f6963e86eff0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8500/8500 [02:52<00:00, 49.42it/s]\n",
      "100%|██████████| 592/592 [00:11<00:00, 53.17it/s]\n"
     ]
    }
   ],
   "source": [
    "x_train_processed = preprocess(x_train)\n",
    "x_test_processed = preprocess(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-ocVxrPv-jay"
   },
   "source": [
    "# Applying Machine Learning \n",
    "For training this model, after doing a bit a research I would be using <b>Transfer Learning</b>\n",
    "### Transfer Learning \n",
    "it is the reuse of a pre trained model on a new problem and is currently popular in the feield of deep learning, because it enables you to train neural network with comparatively less data.\n",
    "It is quite useful since most real-world problems typically do not have millions of labeled data points.\n",
    "In this case I would be using the universal sentence encoder for getting pre trained sentence embedding \n",
    "It converts the sentence into 512 dimensional vector \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "hG22Gl1--jaz",
    "outputId": "2b3d0099-fc1f-454e-979c-d2b990144c3e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0410 16:05:27.916204 139790294316928 __init__.py:56] Some hub symbols are not available because TensorFlow version is less than 1.14\n"
     ]
    }
   ],
   "source": [
    "# importing the necessary libraries\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vBVXkOLj-ja3"
   },
   "source": [
    " Fetching the Universal sentence encoder from TFHub\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "id": "LDy2sIxT-ja4",
    "outputId": "3ffdef67-3eb3-49a2-863f-4b5fa62c6617"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/control_flow_ops.py:3632: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0410 16:05:46.127018 139790294316928 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/control_flow_ops.py:3632: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "url = 'https://tfhub.dev/google/universal-sentence-encoder-large/3'\n",
    "embed = hub.Module(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "U2g7-NJ4-ja7"
   },
   "source": [
    "### Building the model\n",
    "Using Keras to build a neural network having 5 dense layers and few droupout layers to prevent overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0tpemq36-ja7"
   },
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Dropout, LSTM, SpatialDropout1D\n",
    "from keras.models import Sequential\n",
    "import keras.backend as K\n",
    "\n",
    "\n",
    "def our_model():\n",
    "    model = Sequential([\n",
    "        Dense(512, activation='relu', input_dim=512),\n",
    "        Dense(256, activation='relu'),\n",
    "        Dropout(0.25),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dropout(0.25),\n",
    "        Dense(16, activation='relu'),\n",
    "        Dropout(0.1),\n",
    "        Dense(2, activation='softmax')\n",
    "    ])\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bc2JsuZ6-ja-"
   },
   "outputs": [],
   "source": [
    "# function to get embeddings of any input sentence \n",
    "def fetch_embeddings(data):\n",
    "    with tf.Session() as session:\n",
    "        session.run([tf.global_variables_initializer(), tf.tables_initializer()])\n",
    "        embeddings = session.run(embed(data))\n",
    "        return embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2kamnnTP-jbB"
   },
   "source": [
    "Splitting the data into equally sized chunks and getting the embeddings individually as data is quite large is processesed at once "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3jJJHu0A-jbC"
   },
   "outputs": [],
   "source": [
    "processed_train_splits = np.array_split(x_train_processed, 17)\n",
    "processed_train_splits = np.array(processed_train_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 632
    },
    "colab_type": "code",
    "id": "Ze2_zDay-jbF",
    "outputId": "a9093476-1cd2-454d-bdd7-88008db0defb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/17 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0410 16:06:09.890283 139790294316928 saver.py:1483] Saver not created because there are no variables in the graph to restore\n",
      "  6%|▌         | 1/17 [00:34<09:07, 34.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0410 16:06:43.708363 139790294316928 saver.py:1483] Saver not created because there are no variables in the graph to restore\n",
      " 12%|█▏        | 2/17 [01:05<08:21, 33.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0410 16:07:15.615586 139790294316928 saver.py:1483] Saver not created because there are no variables in the graph to restore\n",
      " 18%|█▊        | 3/17 [01:39<07:48, 33.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0410 16:07:49.429284 139790294316928 saver.py:1483] Saver not created because there are no variables in the graph to restore\n",
      " 24%|██▎       | 4/17 [02:06<06:50, 31.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0410 16:08:17.049367 139790294316928 saver.py:1483] Saver not created because there are no variables in the graph to restore\n",
      " 29%|██▉       | 5/17 [02:28<05:44, 28.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0410 16:08:39.233918 139790294316928 saver.py:1483] Saver not created because there are no variables in the graph to restore\n",
      " 35%|███▌      | 6/17 [02:57<05:17, 28.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0410 16:09:08.429210 139790294316928 saver.py:1483] Saver not created because there are no variables in the graph to restore\n",
      " 41%|████      | 7/17 [03:34<05:11, 31.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0410 16:09:45.213114 139790294316928 saver.py:1483] Saver not created because there are no variables in the graph to restore\n",
      " 47%|████▋     | 8/17 [04:00<04:26, 29.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0410 16:10:11.713491 139790294316928 saver.py:1483] Saver not created because there are no variables in the graph to restore\n",
      " 53%|█████▎    | 9/17 [04:28<03:52, 29.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0410 16:10:39.685369 139790294316928 saver.py:1483] Saver not created because there are no variables in the graph to restore\n",
      " 59%|█████▉    | 10/17 [05:04<03:37, 31.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0410 16:11:16.232179 139790294316928 saver.py:1483] Saver not created because there are no variables in the graph to restore\n",
      " 65%|██████▍   | 11/17 [05:28<02:54, 29.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0410 16:11:40.733540 139790294316928 saver.py:1483] Saver not created because there are no variables in the graph to restore\n",
      " 71%|███████   | 12/17 [05:52<02:17, 27.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0410 16:12:04.967576 139790294316928 saver.py:1483] Saver not created because there are no variables in the graph to restore\n",
      " 76%|███████▋  | 13/17 [06:20<01:50, 27.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0410 16:12:33.195945 139790294316928 saver.py:1483] Saver not created because there are no variables in the graph to restore\n",
      " 82%|████████▏ | 14/17 [06:50<01:25, 28.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0410 16:13:04.258862 139790294316928 saver.py:1483] Saver not created because there are no variables in the graph to restore\n",
      " 88%|████████▊ | 15/17 [07:19<00:57, 28.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0410 16:13:32.905250 139790294316928 saver.py:1483] Saver not created because there are no variables in the graph to restore\n",
      " 94%|█████████▍| 16/17 [07:51<00:29, 29.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0410 16:14:05.375823 139790294316928 saver.py:1483] Saver not created because there are no variables in the graph to restore\n",
      "100%|██████████| 17/17 [08:20<00:00, 29.32s/it]\n"
     ]
    }
   ],
   "source": [
    "processed_train_embeddings = []\n",
    "\n",
    "for split in tqdm.tqdm(processed_train_splits):\n",
    "    embedding = fetch_embeddings(split)\n",
    "    processed_train_embeddings.append(embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "fjcgaXGd-jbM",
    "outputId": "1713b93d-111d-444a-be87-fba8d4a03b8c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8500, 512)"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_train_embeddings = np.array(processed_train_embeddings)\n",
    "processed_train_embeddings = processed_train_embeddings.reshape(-1, processed_train_embeddings.shape[-1])\n",
    "processed_train_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "ug54i2Y4-jbR",
    "outputId": "0dd605e5-bfcc-4b8a-e55d-7b2127f987ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0410 16:16:48.132393 139790294316928 saver.py:1483] Saver not created because there are no variables in the graph to restore\n"
     ]
    }
   ],
   "source": [
    "processed_test_embeddings = fetch_embeddings(x_test_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "id": "0Sg545cY-jbV",
    "outputId": "e0773056-0f52-4aa6-f9f2-b52fdef619c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0410 16:17:20.736626 139790294316928 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "model = our_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 408
    },
    "colab_type": "code",
    "id": "LWWpKBEF-jbY",
    "outputId": "f95b2a12-3028-4f7b-cb5d-2b177b3904b8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 16)                1040      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 2)                 34        \n",
      "=================================================================\n",
      "Total params: 411,506\n",
      "Trainable params: 411,506\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r2EE_IBV-jbb"
   },
   "source": [
    "### Training the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 513
    },
    "colab_type": "code",
    "id": "u8C7Xam1-jbc",
    "outputId": "db256187-edbd-483b-835d-d0f53fdc1acc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0410 16:17:35.290950 139790294316928 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7650 samples, validate on 850 samples\n",
      "Epoch 1/10\n",
      "7650/7650 [==============================] - 16s 2ms/step - loss: 0.5446 - acc: 0.7554 - val_loss: 0.4761 - val_acc: 0.6553\n",
      "Epoch 2/10\n",
      "7650/7650 [==============================] - 1s 70us/step - loss: 0.3727 - acc: 0.7680 - val_loss: 0.3914 - val_acc: 0.6718\n",
      "Epoch 3/10\n",
      "7650/7650 [==============================] - 1s 70us/step - loss: 0.3356 - acc: 0.8443 - val_loss: 0.3764 - val_acc: 0.8600\n",
      "Epoch 4/10\n",
      "7650/7650 [==============================] - 1s 68us/step - loss: 0.3108 - acc: 0.8782 - val_loss: 0.3212 - val_acc: 0.8788\n",
      "Epoch 5/10\n",
      "7650/7650 [==============================] - 1s 67us/step - loss: 0.2826 - acc: 0.8810 - val_loss: 0.2780 - val_acc: 0.8847\n",
      "Epoch 6/10\n",
      "7650/7650 [==============================] - 1s 66us/step - loss: 0.2657 - acc: 0.8893 - val_loss: 0.2809 - val_acc: 0.8871\n",
      "Epoch 7/10\n",
      "7650/7650 [==============================] - 1s 67us/step - loss: 0.2441 - acc: 0.8999 - val_loss: 0.3141 - val_acc: 0.8765\n",
      "Epoch 8/10\n",
      "7650/7650 [==============================] - 1s 72us/step - loss: 0.2336 - acc: 0.9064 - val_loss: 0.3459 - val_acc: 0.8659\n",
      "Epoch 9/10\n",
      "7650/7650 [==============================] - 1s 71us/step - loss: 0.2204 - acc: 0.9146 - val_loss: 0.2909 - val_acc: 0.8835\n",
      "Epoch 10/10\n",
      "7650/7650 [==============================] - 1s 70us/step - loss: 0.1879 - acc: 0.9311 - val_loss: 0.2949 - val_acc: 0.8953\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f230e52fcc0>"
      ]
     },
     "execution_count": 21,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(processed_train_embeddings, y_train_con, validation_split=0.1, epochs=10, batch_size=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "ATKU4rLE-jbg",
    "outputId": "50d1ebef-6a11-46cf-b59e-59f84ec6f48b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "592/592 [==============================] - 0s 76us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5169495505255621, 0.8125]"
      ]
     },
     "execution_count": 22,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluating the performance of the model\n",
    "model.evaluate(processed_test_embeddings, y_test_con)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "J1bJDptn-jbk"
   },
   "source": [
    "### Evaluating the model\n",
    "Creating a simple class that shows the performance of the model on the basis of various criterias, so that better understanding can be made.\n",
    "Could be used in future for comparing two models \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V4iOtyM9-jbk"
   },
   "outputs": [],
   "source": [
    "class evaluateModel():\n",
    "  def __init__(self, y_true, y_pred):\n",
    "    self.y_true = y_true\n",
    "    self.y_pred = y_pred\n",
    "  \n",
    "  def plot_cm(self):\n",
    "    cm = confusion_matrix(self.y_true, self.y_pred)\n",
    "    sns.heatmap(cm, annot=True,fmt='d')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.show()\n",
    "  \n",
    "  def get_accuracy(self):\n",
    "    print(accuracy_score(self.y_true, self.y_pred))\n",
    "  \n",
    "  def get_report(self):\n",
    "    print(classification_report(self.y_true, self.y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Es5Svtut-jbn"
   },
   "source": [
    "#### Making Predictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CY8WnAct-jbn"
   },
   "outputs": [],
   "source": [
    "predicts = model.predict(processed_test_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "59VxYn3X-jbr"
   },
   "outputs": [],
   "source": [
    "y_predict = np.argmax(predicts, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "P4zhohXC-jbt",
    "outputId": "a8c8403c-90d1-4c19-ec85-2ede87a1a225"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((592,), (592,))"
      ]
     },
     "execution_count": 26,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking predictions are working fine\n",
    "y_test.shape, y_predict.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j-aa05eA-jbw"
   },
   "outputs": [],
   "source": [
    "evaluate = evaluateModel(y_test, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "PyncpA5F-jby",
    "outputId": "e92cf4b6-fa64-4bb2-a167-0b59f8b0d890"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.87      0.82       296\n",
      "           1       0.85      0.76      0.80       296\n",
      "\n",
      "   micro avg       0.81      0.81      0.81       592\n",
      "   macro avg       0.82      0.81      0.81       592\n",
      "weighted avg       0.82      0.81      0.81       592\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# seeing the report \n",
    "evaluate.get_report()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MA9b7y_6-jb1"
   },
   "source": [
    "#### Model achieves a decent accuracy of 81.25%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "gYoORof_-jb2",
    "outputId": "5b550a3e-1bf2-44e2-c22d-778b645331a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8125\n"
     ]
    }
   ],
   "source": [
    "evaluate.get_accuracy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_XS0uCKT-jb5"
   },
   "source": [
    "Using confusion matrix to help in visualizing the predictios of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 361
    },
    "colab_type": "code",
    "id": "jiqJ3GSq-jb7",
    "outputId": "1b3ceeb4-32c7-4d3f-a535-fb6c2b26dccb"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAc8AAAFYCAYAAAA1G3fQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAH65JREFUeJzt3XlclWXex/HvYTkiBQrKcVIbMqds\nQ9Iglxb3yprKeVwwktKYFgfLHDKXHJdER6yp1IfcMjXIlayYxi0zG2YeMh1M0WccNcuFTKBEChQF\nzvNHdZ5hVOBGj5c3fN69zuvluc99rvPD1wxff9d93ddxuN1utwAAQI35mC4AAAC7ITwBALCI8AQA\nwCLCEwAAiwhPAAAsIjwBALDIz3QB59I2vIvpEoDztjVnlekSgAvCGdzEa2Ofz+/7HQc+uYCV1Nwl\nG54AgPrB4XCYLsEypm0BALCIzhMAYJTDYb8+zn4VAwBgGJ0nAMAoH9nvmifhCQAwyo4LhghPAIBR\nPja85kl4AgCMsmPnab+4BwDAMMITAACLmLYFABjlYLUtAADWsGAIAACL7LhgiPAEABjlY8PwtF+v\nDACAYYQnAAAWMW0LADDKYcM+jvAEABjFgiEAACxiwRAAABY5zuO/6kyfPl0xMTHq27ev1q9f7zme\nmZmpNm3aeJ5nZGSob9++6t+/v1auXFntuHSeAIA66dNPP9XevXu1fPlyHTt2TL/5zW901113qbS0\nVPPmzVNYWJgkqaSkRCkpKUpPT5e/v7/69eunXr16qXHjxuccm84TAFAnRUdHa8aMGZKk4OBgnThx\nQuXl5ZozZ45iY2PldDolSdu3b1dERISCgoIUEBCg9u3bKzs7u8qxCU8AgFE+Dp9aP6ri6+urwMBA\nSVJ6erruvPNOHTx4ULt371bv3r095xUUFCg0NNTzPDQ0VPn5+VWOzbQtAMAob6+23bBhg9LT0/Xm\nm28qMTFR48aNq/J8t9td7Zh0ngAAo3wcjlo/qpOZmak5c+Zo/vz5Kikp0f79+/Xcc89pwIABysvL\n06BBg+RyuVRQUOB5T15enlwuV5Xj0nkCAIzy1leSff/995o+fboWLVrkWfyzYcMGz+vdu3dXWlqa\nTp48qXHjxqmoqEi+vr7Kzs7W2LFjqxyb8AQA1EmrV6/WsWPH9Oyzz3qOJScnq3nz5pXOCwgIUGJi\nouLj4+VwOJSQkKCgoKAqx3a4azK5a0Db8C6mSwDO29acVaZLAC4IZ3ATr43dO2Jgrd+7JmfZBayk\n5rjmCQCARUzbAgCMYm9bAAAssuPetoQnAMAob6229SaueQIAYBGdJwDAKK55AgBgkR2veTJtCwCA\nRXSeAACj7LhgiPAEABhV3VeLXYrsVzEAAIbReQIAjGK1LQAAFtlxtS3hCQAwyo4LhrjmCQCARXSe\nAACj7DhtS+cJAIBFdJ4AAKNYbQsAgEV2nLYlPAEARtlxtS3hCQAwyo6dJwuGAACwiPAEAMAipm0B\nAEax2hYAAIvseM2T8AQAGMVqWwAALLJj58mCIQAALCI8AQCwiGlbAIBRrLYFAMAiO17zJDwBAEbR\neQIAYJEdb1VhwRAAABbReQIAjPKxX+NJ5wkAgFV0ngAAo1gwBACARdyqAgCARXbsPLnmCQCARXSe\ndVjXnp31u98/JmcDpwqPHVfS2Fd0Q9s2GjXhaRXkfes5b+lb72rZ4ne1YNlrahoW6jneOLSRMt5Z\npz8lvW6ifOCsPtz4sea+sUilp0oV0rix/jB6pFpdFa5XZ72uv/79f1RaWqqHBvTTkLiHTZeKGvKx\n4X2ehGcd5WrWVEmvjNUjfRO0f+8BxcT10R/+mKh3ln6gjesy9Yfnpp3xnviBz3r+7OPjo6UfzNOf\n31l3McsGqnTkm280+Y8vadlbC9T8iiuUtnS5xk+eqj7336ecXf+r9LcX69Tp03p4yONqe9ONuqXd\nzaZLRg0wbYtLRllZmUY9/aL27z0gScreskOtr7mqxu/vF3u//rlzj/b88wsvVQhY5+fnp2lJE9X8\niiskSR2io/TVgYPK2rxF997dSw0aNFDQ5Zerz/33acPGTUZrRd3m1c6zuLhYBQUFkqSwsDAFBgZ6\n8+Pwb777tlB//+Qzz/Pbu3ZQzuf/lCS1ueFXWrDsNYU1a6rsLTv08uQU/fB9sedcP38/PTY0tlIn\nClwKwpo2VVjTppJ+/Afi+x+sVrcud+jEiZMqr6jwnBfYsKEOHj5sqkxYxGrbn+Tk5GjKlCkqKipS\nSEiI3G638vLy1KxZM40fP15t2rTxxsfiHDrc1l5x8f3129gRCgq+XJs+/LsWzVumivIKJb0yViPH\nD9OEkcme8+/r00s7t+9W7qEjBqsGzi1t6XLNWbBQv2zZUjNenqaPP8nUinfe0/333qOK8gr9ec1a\nNQxoaLpM1JANs9M74Tl16lRNmTJFrVu3rnR8165devHFF/X2229742NxFt3uul1jJg3XsMfGeKZw\nt/9jl+f1Ba+nafbilyq9594He2pF2nsXtU7AikEPxejhgQO0Zv2Hiot/Uu8seUuHDufq4cGPq2nT\nJup0663a/+WXpsvEJWD69On6xz/+obKyMj355JOKiIjQ888/r/LycoWFhemll16S0+lURkaGFi9e\nLB8fHw0YMED9+/evclyvXPN0u91nBKck3XjjjSovL/fGR+IsOtx2i0ZNeFpPxj2n/835lySp2RVh\nCglt5DnH19dXp8vKPM8DL2uoyPY3KCtz60WvF6jO/i+/UtbmLZJ+XGRy79136YfiYh06nKvE4cP0\n53eWaeHcFPn6+uqaX535OwiXJh+Ho9aPqnz66afau3evli9frjfeeENTp07VzJkzFRsbqyVLlig8\nPFzp6ekqKSlRSkqKFi1apNTUVC1evFiFhYVV13wh/wJ+FhkZqaeeekrp6enauHGjNm7cqBUrVig+\nPl633nqrNz4S/yEgoIEmvzxaI578g77cd8BzPGZQH02YNlJ+fr7y8fHRQ4P7KnPjp57Xr/5VuI59\nd1wlxSdMlA1U6btjx/TCxMnKy8+XJG3bvkNlZWX61959Gjn2D6qoqFBefr7e/2C17rvnbsPVoqYc\n5/FfVaKjozVjxgxJUnBwsE6cOKHNmzerR48ekqRu3bopKytL27dvV0REhIKCghQQEKD27dsrOzu7\nyrG9Mm07ZswYbdmyRVlZWdqxY4ckyeVyadiwYWrXrp03PhL/odtdtysktJGmzRhX6fhTj4zU70YM\n0bsb3pK7okKf/2OXXpk62/N6syvCVJD/3cUuF6iRqPbt9PiQR/V4wnBVVFTI6XRq+pQXFdW+nT7+\nJFP3/qa/fH199eywofrllS1Nl4sa8tatKr6+vp6Fqunp6brzzjv1t7/9TU6nU5LUpEkT5efnq6Cg\nQKGh/3+Pe2hoqPJ/+gfauXhttW10dLSio6O9NTyqsSbjI63J+Oisr53tHs+ffbQ2Ux+tzfRWWcB5\ne2hAXz00oO8Zx1976Y8GqoEdbNiwQenp6XrzzTd11113eY673e6znn+u4/+O+zwBAEZ565qnJGVm\nZmrOnDmaP3++goKCFBgYqJMnT0qSjh49KpfLJZfL5bmtUpLy8vLkcrmqrvn8fmQAAM6Pw1H7R1W+\n//57TZ8+XXPnzlXjxo0lSZ07d9a6dT/unLZ+/XrdcccdioyMVE5OjoqKilRcXKzs7GxFRUVVOTbb\n8wEA6qTVq1fr2LFjevbZ/9/wZdq0aRo3bpyWL1+u5s2bq0+fPvL391diYqLi4+PlcDiUkJCgoKCg\nKsd2uGsyuWtA2/AupksAztvWnFWmSwAuCGdwE6+NPeHeF2r93kmrp1zASmqOzhMAYFR1t5xcighP\nAIBRdtzblgVDAABYROcJADDKho0nnScAAFbReQIAjPLW9nzeRHgCAIyy44IhwhMAYJQNs5PwBACY\nZcfOkwVDAABYRHgCAGAR07YAAKPYng8AAIu4VQUAAIt87JedhCcAwCw7dp4sGAIAwCLCEwAAi5i2\nBQAYZcdpW8ITAGAUC4YAALCIzhMAAItsmJ0sGAIAwCo6TwCAUXyrCgAA9QCdJwDAKDaGBwDAIhvO\n2hKeAACzuOYJAEA9QOcJADCKTRIAALDIhtnJtC0AAFbReQIAjGLaFgAAi+z4rSpM2wIAYBGdJwDA\nKKZtAQCwyIbZSXgCAMxihyEAAOoBOk8AgFF2vOZJ5wkAgEV0ngAAo2zYeBKeAACz7DhtS3gCAIyy\nYXYSngAAs7hVBQCAeoDwBADAIsITAGCUw1H7R3X27Nmjnj17Ki0tTZJ0+vRpJSYmql+/fnr00Ud1\n/PhxSVJGRob69u2r/v37a+XKldWOS3gCAIxyOBy1flSlpKREkydPVqdOnTzHVqxYoZCQEKWnp+ve\ne+/V1q1bVVJSopSUFC1atEipqalavHixCgsLqxyb8AQAGOWtztPpdGr+/PlyuVyeYx9//LEeeOAB\nSVJMTIx69Oih7du3KyIiQkFBQQoICFD79u2VnZ1d5diEJwDAKG91nn5+fgoICKh0LDc3V3/9618V\nFxenESNGqLCwUAUFBQoNDfWcExoaqvz8/CrHJjwBAPWG2+1Wq1atlJqaqmuuuUZz58496znVITwB\nAPVG06ZNFR0dLUm6/fbbtW/fPrlcLhUUFHjOycvLqzTVezaEJwDAKG+utv1Pd955pzIzMyVJu3bt\nUqtWrRQZGamcnBwVFRWpuLhY2dnZioqKqnIcdhgCABjlrR2Gdu7cqeTkZOXm5srPz0/r1q3Tyy+/\nrClTpig9PV2BgYFKTk5WQECAEhMTFR8fL4fDoYSEBAUFBVU5tsNdk8ldA9qGdzFdAnDetuasMl0C\ncEE4g5t4bez3np5Z6/f2mfXMBayk5ug8AQBG2fFbVbjmCQCARTUKz2PHjiknJ0eSVFFR4dWCAAD1\ny8VcMHShVBueH3zwgWJiYjRmzBhJ0uTJk2u07x8AAHVVteG5cOFCvf/++woJCZEkjRo1SitWrPB6\nYQCA+sFbOwx5U7ULhoKCgtSwYUPP84CAAPn7+3u1KABA/WHD9ULVh2dISIjeffddlZaWateuXVq9\nenWlPQABADgfdXK17aRJk5STk6Pi4mKNGzdOpaWlSkpKuhi1AQBwSaq28wwODtb48eMvRi0AgHrI\nho1n9eHZpUuXs7bUmzZt8kY9AIB6xo7TttWG55IlSzx/Pn36tLKyslRaWurVogAAuJRVG54tWrSo\n9Pyqq65SfHy8Bg8e7K2aAAD1iA0bz+rDMysrq9Lzb775RgcPHvRaQT/b+M40r38G4G2P9hhlugTg\ngli65Q2vje2tb1XxpmrD8/XXX/f82eFw6PLLL9ekSZO8WhQAoP6wYXZWH56jR4/WjTfeeDFqAQDA\nFqq9zzM5Ofli1AEAqKfq5PZ8zZs3V1xcnCIjIyttyzd8+HCvFgYAqB/sOG17zs4zIyNDktSyZUt1\n6NBBAQEB8vX19TwAAKivztl5pqen64EHHtCwYcMuZj0AgHrG4WO/1rPaaVsAALzJjtO25wzPbdu2\nqWvXrmccd7vdcjgcbM8HAKi3zhmeN9xwg1555ZWLWQsAoB6qU3vbOp3OM7bmAwDgQrNhdp47PNu2\nbXsx6wAA1FN27DzPeavKyJEjL2YdAADYBqttAQBG2bDxrH57PgAAUBmdJwDALBu2noQnAMAoOy4Y\nIjwBAEbZMDsJTwCAWXbc25YFQwAAWER4AgBgEdO2AACjuOYJAIBFrLYFAMAiG2Yn4QkAMMuOnScL\nhgAAsIjwBADAIqZtAQBG2XDWlvAEAJhlx2uehCcAwCwbXkAkPAEARtmx87Rh3gMAYBbhCQCARUzb\nAgCMsuGsLZ0nAMAsh8NR60d19uzZo549eyotLU2SdOTIEQ0ePFiDBg3S4MGDlZ+fL0nKyMhQ3759\n1b9/f61cubLacQlPAIBRDkftH1UpKSnR5MmT1alTJ8+x1157TQMGDFBaWpp69eqlhQsXqqSkRCkp\nKVq0aJFSU1O1ePFiFRYWVjk24QkAMMtL6el0OjV//ny5XC7PsQkTJujuu++WJIWEhKiwsFDbt29X\nRESEgoKCFBAQoPbt2ys7O7vKsQlPAECd5Ofnp4CAgErHAgMD5evrq/Lyci1ZskT333+/CgoKFBoa\n6jknNDTUM517LoQnAMAoh4+j1o/aKC8v1/PPP6+OHTtWmtL9mdvtrnYMwhMAUK+MGTNG4eHhGjZs\nmCTJ5XKpoKDA83peXl6lqd6zITwBAEZ5a8HQ2WRkZMjf31/PPPOM51hkZKRycnJUVFSk4uJiZWdn\nKyoqqspxuM8TAGCUt7bn27lzp5KTk5Wbmys/Pz+tW7dO3377rRo0aKC4uDhJUuvWrTVx4kQlJiYq\nPj5eDodDCQkJCgoKqnJswhMAYJS3Nkm46aablJqaWqNz77nnHt1zzz01HptpWwAALKLzBACYZcP9\n+QhPAIBRtb3lxCSmbQEAsIjOEwBglA1nbQlPAIBhNkxPpm0BALCIzhMAYJQNG0/CEwBglh1X2xKe\nAACjvLU9nzdxzRMAAIvoPAEAZtmv8aTzBADAKjpPAIBRdrzmSXgCAIwiPAEAsMqGFxAJTwCAUXbs\nPG2Y9wAAmEV4AgBgEdO2AACj7DhtS3gCAMyyX3YSngAAs9gYHgAAq2w4bcuCIQAALCI8AQCwiGnb\neuDjzVs0b+U7lY4dPPKN1r8xW3NXpGtLzi653W61v+F6/X5wnPx8fQ1VCpzdLXdGqt+TD8rf31/f\nH/9BC6al6vAXX+s38b/Wbfd0kI/Doa/2HNL8KW/pRPEJz/scDodefHOMcr86ojmTFhr8CVAVG87a\nEp71QbcO0erWIdrz/KNPP9NHn27W+xs36eDX3+itaUmSpGemJGv1J5l6oHtXM4UCZxES1lhPTXhM\nE387TblfHlGvfl312zGPaPWSD9WxZ5TGPZqk0hOnNCzpcd3/yD1aMftdz3t79uuqRqHByv3qiMGf\nANWx460qTNvWM6WnTmn+ynf0u4didPN1bTTi0Yfl7+cnfz8/Xd/6au3PzTVdIlBJeVm5/nvcPOV+\n+WMA/uvzfWp5dXN9/VM3ebKkVG63W3t2fKGWVzf3vK9xk0a6e0B3rV76oanSUVM+jto/DLnonWdR\nUZGCg4Mv9sfiJx9s+qsirr1GLZu5pGYuz/Gy8nJtydmlRx78tcHqgDMVHfte27N2eZ5Hdr5J+3bu\n1+H9X1c67+bON2n3tj2e548kDtSq+X+Wn5MJtksdnWcNDBs27GJ/JH5SUVGhZavX6aH7elc67na7\n9aeFb8kVGqLuHW81VB1QvRujr9O9sb2U+urySsf7DLlPjUKDtXbZR5KkyE436rKgQP3P+s9MlIl6\nwCv/JHv77bfP+drRo0e98ZGogZ17v1DDgAa6umULz7Gy8nL9cd4CFRZ9r6kjnpavDzP5uDRFdblZ\ng0fG6qURMz1TuJI0MOG/FNHhRv1x2KsqPXlK/g389fDwAfrTcykGq4Ul9ms8vROeixYtUqdOneRy\nuc54rayszBsfiRr4+7bP1enmtpWOJb+xUKWnTik5cbj8/JjewqXppluv1yOJD2nqsFf19b8t/un7\n+AO6tu2vNPmp6TpZUipJuvq6cIW6QjTxjVGSJGcDf/n5+Sm4cZCmj5hppH7UPV75bZmSkqKkpCSN\nGzdOTqez0mubN2/2xkeiBvYdPKQe/zYtu2nLVn2V+7Vmjx9LcOKS5Wzg1FPjh+hPz6VUCs5W14Xr\njvs6aczDL3qCU5L+tX2fftv9Gc/zO3/dWTfc0oZbVS5hdrzm6ZXfmNdee63mzp171l/Io0eP9sZH\nogbyv/tOTRo38jx//6NNOpJfoLjR4zzHIq69RmOfiDdRHnBWUV1uVlDjICVM/m2l43tz9uuyywM1\nedFYz7GCI99q2jOvXewScZ7suLetw+12u00XcTYFW7NMlwCct6eHLjBdAnBBLN3yhtfGPvSXNbV+\n75X/sQDyYmGuDgBglB2nbVlaCQCARXSeAACz7Nd40nkCAGAVnScAwCg7rrYlPAEAZtlwwRDhCQAw\nitW2AADUA3SeAACzuOYJAIA1TNsCAFAP0HkCAMzyUuNZXFysUaNG6fjx4zp9+rQSEhIUFhamiRMn\nSpLatGmjSZMm1WpswhMAYJS3pm3fffddtWrVSomJiTp69KgeffRRhYWFaezYsWrbtq0SExP1ySef\nqEuXLpbHZtoWAFAnhYSEqLCwUJJUVFSkxo0bKzc3V23btpUkdevWTVlZtfsGL8ITAGCWj6P2jyrc\nd999+vrrr9WrVy8NGjRIzz//vIKDgz2vN2nSRPn5+bUqmWlbAIBR3pq2ff/999W8eXMtWLBAu3fv\nVkJCgoKCgjyvn8/XWROeAACzvBSe2dnZuv322yVJ1113nUpLS1VWVuZ5/ejRo3K5XLUam2lbAECd\nFB4eru3bt0uScnNzddlll6l169baunWrJGn9+vW64447ajU2nScAwChvTdvGxMRo7NixGjRokMrK\nyjRx4kSFhYVp/PjxqqioUGRkpDp37lyrsQlPAECddNlll2nGjBlnHF+yZMl5j014AgDMYm9bAACs\nsePetoQnAMAswhMAAGscNpy25VYVAAAsIjwBALCIaVsAgFlc8wQAwBpW2wIAYBXhCQCANay2BQCg\nHiA8AQCwiGlbAIBZXPMEAMAiwhMAAGu4VQUAAKtYbQsAQN1H5wkAMMrhsF8fZ7+KAQAwjM4TAGAW\nC4YAALCG1bYAAFjFalsAAOo+Ok8AgFFM2wIAYJUNw5NpWwAALKLzBACYZcNNEghPAIBRDlbbAgBQ\n99F5AgDMsuGCIcITAGAUt6oAAGCVDRcM2a9iAAAMo/MEABjFalsAAOoBOk8AgFksGAIAwBpW2wIA\nYJUNV9sSngAAs1gwBABA3Ud4AgBgEdO2AACjWDAEAIBVLBgCAMAaOk8AAKyyYedpv4oBADCM8AQA\n1GknT55Uz549tWrVKh05ckRxcXGKjY3V8OHDderUqVqNSXgCAIxy+Dhq/aiJ2bNnq1GjRpKkmTNn\nKjY2VkuWLFF4eLjS09NrVTPhCQAwy+Go/aMaX3zxhfbt26euXbtKkjZv3qwePXpIkrp166asrKxa\nlUx4AgCMcjh8av2oTnJyskaPHu15fuLECTmdTklSkyZNlJ+fX6uaWW0LADDLS7eqvPfee7r55pt1\n5ZVXnvV1t9td67Ev2fBsGtXJdAnAeVu6hf8dA9VxBjfxyribNm3SoUOHtGnTJn3zzTdyOp0KDAzU\nyZMnFRAQoKNHj8rlctVqbIf7fKIXAAAbmDVrllq0aKFt27YpKipKDz74oJKSktSmTRv179/f8nhc\n8wQA1BtPP/203nvvPcXGxqqwsFB9+vSp1Th0ngAAWETnCQCARYQnAAAWEZ4AAFhEeNZTU6dOVUxM\njAYOHKgdO3aYLgeotT179qhnz55KS0szXQrqkUv2Pk94z2effaYDBw5o+fLl+uKLLzR27FgtX77c\ndFmAZSUlJZo8ebI6deJ+WlxcdJ71UFZWlnr27ClJat26tY4fP64ffvjBcFWAdU6nU/Pnz6/1je5A\nbRGe9VBBQYFCQkI8z0NDQ2u9vyNgkp+fnwICAkyXgXqI8MR57e8IAPUR4VkPuVwuFRQUeJ7n5eUp\nLCzMYEUAYC+EZz102223ad26dZKkXbt2yeVy6fLLLzdcFQDYB9vz1VMvv/yytm7dKofDoQkTJui6\n664zXRJg2c6dO5WcnKzc3Fz5+fmpWbNmmjVrlho3bmy6NNRxhCcAABYxbQsAgEWEJwAAFhGeAABY\nRHgCAGAR4QkAgEWEJyDp8OHDuummmxQXF6e4uDgNHDhQiYmJKioqqtV4K1eu1OjRoyVJI0aM0NGj\nR895bnZ2tg4dOlTjscvKytSmTZta1QXgwiA8gZ+EhoYqNTVVqampWrZsmVwul2bPnn3e47766qtq\n1qzZOV9ftWqVpfAEYB5fSQacQ3R0tJYvX67u3burd+/eOnTokGbOnKnVq1crLS1NbrdboaGhSkpK\nUkhIiN5++20tXbpUv/jFLyp9y0f37t21cOFCXXnllUpKStLOnTslSUOGDJGfn5/Wrl2rHTt2aMyY\nMQoPD9ekSZN04sQJlZSU6Pe//706d+6s/fv3a+TIkWrYsKE6dOhg6q8EwE8IT+AsysvL9eGHH+qW\nW27R3r17ddVVV2nkyJE6cuSI5syZo/T0dDmdTi1evFhz585VQkKCZs6cqbVr1yokJERDhw5Vo0aN\nKo2ZkZGhgoICrVixQkVFRXruuec0e/ZsXX/99Ro6dKg6deqkJ554Qo899pg6duyo/Px8xcTEaP36\n9UpJSVHfvn0VGxur9evXG/pbAfAzwhP4yXfffae4uDhJUkVFhaKiojR48GAtW7ZM7dq1kyRt27ZN\n+fn5io+PlySdOnVKLVu21IEDB9SiRQvPV7116NBBu3fvrjT+jh07PF1jcHCw5s2bd0YNmzdvVnFx\nsVJSUiT9+JVb3377rfbs2aMnnnhCktSxY0cv/PQArCA8gZ/8fM3zbPz9/SX9+OXLbdu21dy5cyu9\nnpOTI4fD4XleUVFxxhgOh+Osx/+d0+nUrFmzFBoaWum42+2Wj8+PSxTKy8ur/2EAeBULhgALIiIi\ntGPHDs+Xh69Zs0YbNmzQL3/5Sx0+fFhFRUVyu93Kyso6473t2rVTZmamJOmHH35Q//79derUKTkc\nDp0+fVqSdMstt2jNmjWSfuyEp0yZIklq3bq1Pv/8c0k669gALi46T8CCZs2a6YUXXtCTTz6phg0b\nKiAgQMnJyWrUqJGeeuopPfzww2rRooVatGihkydPVnpv7969lZ2drYEDB6q8vFxDhgyR0+nUbbfd\npgkTJmjs2LF64YUXNH78eP3lL3/RqVOnNHToUElSQkKCRo0apbVr16pdu3by8+P/uoBJfKsKAAAW\nMW0LAIBFhCcAABYRngAAWER4AgBgEeEJAIBFhCcAABYRngAAWER4AgBg0f8BtITLQcLUeGYAAAAA\nSUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 576x396 with 2 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluate.plot_cm()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v9QRDX4u-jb-"
   },
   "source": [
    "### Finally making the predictions for the evaluation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "Hrn13tXy-jb_",
    "outputId": "1a6854ee-d218-41fc-a3af-0dd7bde7b500"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0410 16:19:33.562204 139790294316928 saver.py:1483] Saver not created because there are no variables in the graph to restore\n"
     ]
    }
   ],
   "source": [
    "eval_embeddings = fetch_embeddings(x_eval.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y-D_SGol-jcC"
   },
   "outputs": [],
   "source": [
    "eval_predicts = model.predict(eval_embeddings)\n",
    "eval_preds = np.argmax(eval_predicts, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yLzzNc0CFDU6"
   },
   "source": [
    "### adding the predicts to the evaluation dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZRVu4NnlDWw3"
   },
   "outputs": [],
   "source": [
    "evaluation[2] = eval_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "GKYPyeJlDcpa",
    "outputId": "eca56faf-6c1e-4739-8677-8b78795e171b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    758\n",
       "1     75\n",
       "Name: 2, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation[2].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sLPPTXfdFQXY"
   },
   "source": [
    "#### Converting the predictions to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J0lu_MYvDpcH"
   },
   "outputs": [],
   "source": [
    "evaluation.to_csv('achintya_shankhdhar.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lUh-KdmmD_4j"
   },
   "outputs": [],
   "source": [
    "from google.colab import files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2EYl7OHqEJ4t"
   },
   "outputs": [],
   "source": [
    "files.download('achintya_shankhdhar.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jUIHMiEFERXI"
   },
   "source": [
    "### Another possible approach\n",
    "\n",
    "One can use Recurrent Neural Networks instead of using conventional dense network, since it has been seen that RNNs have performed well when it comes to text data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "NLP.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
